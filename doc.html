<html>
<head>
<title>ナイーブベイズ分類器 (Naive Bayes Classifier) の GoLang による実装</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body text="white" bgcolor="black" alink="white" vlink="white">

<p>
<b>ナイーブベイズ分類器 (Naive Bayes Classifier) の GoLang による実装</b>
</p>

<p>最終更新日：2020/01/04</p>

<hr>
<p><b>1. はじめに</b></p>

<p>「分類器」とは、ある文書を入力するとその文書が属するカテゴリを推定し出力するシステムである。本稿はこの分類器をナイーブベイズを用いたモデルで示し、そして GoLang による実装例を示す。
</p>

<p>本稿では多項分布のパラメータ推定として最尤推定値 (MLE) と 期待事後確率推定値 (EAP 推定値) を使用するが、具体的な計算については別紙を参照されたい。</p>

<p>参考：<a href="multinomial_distribution.html" target="_blank">多項分布のパラメータ推定</a></p>

<hr>

<p><b>2. 推定</b></p>

<p>
	本節では、与えられた文書に対するカテゴリの推定について示す。
</p>

<hr>
<p><b>2.1 PredictCat (暫定版)</b></p>

<p>
ある文書 \(D\) が与えられたときに、それがカテゴリ \(C\) に属する確率を \(P(C|D)\) と表す。 


</p>

<p>
カテゴリが \(n\) 個あり、\(C_1, ..., C_i, ..., C_n\) のいずれかのとき、
ある文書 \(D\) の属するカテゴリは \(P(C_i|D)\) が最大となる \(C_i\) で与える。

</p>

<p>
例：ニュースのカテゴリ群が \(\{\)社会,政治,国際,スポーツ,科学\(\}\) の 5 種類とする。
あるニュースの文書 \(D\) が与えられそれぞれのカテゴリの確率が以下のとき、 \(D\) の属するカテゴリは  \(P(C_i|P)\) が最大の値となる「スポーツ」となる。

<center>
<table border="1" cellspacing="0" cellpadding="5">
    <tr>
        <td align="center">\(C_i\)</td>
        <td align="center">\(P(C_i|D)\)</td>
    </tr>
    <tr>
        <td align="center">社会</td>
        <td align="center">0.12</td>
    </tr>
    <tr>
        <td align="center">政治</td>
        <td align="center">0.17</td>
    </tr>
    <tr>
        <td align="center">国際</td>
        <td align="center">0.05</td>
    </tr>
    <tr>
        <td align="center">スポーツ</td>
        <td align="center">0.51</td>
    </tr>
    <tr>
        <td align="center">科学</td>
        <td align="center">0.15</td>
    </tr>
</table>
</center>
</p>

<p>
\(P(C_i|D)\) を求める関数を ProbCatGivenDoc とする。

ある文書がどのカテゴリに属するかを推定する関数 PredictCat は
すべてのカテゴリについて ProbCatGivenDoc を計算していき、
その値が最大となるときのカテゴリを決定すればよいので、
実装は次のようになる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// catList : カテゴリのリスト
var catList []TypeCat

// PredictCat : 与えられた文書 doc のカテゴリを推定する関数。暫定版。
func PredictCat(doc TypeDoc) (cat TypeCat) {
	cat = catList[0]
	maxValue := ProbCatGivenDoc(doc, cat)
	for i:=1; i&lt;len(catList); i++ {
		result := probCatGivenDoc(doc, catList[i])
		if result &gt; maxValue {
			maxValue = result
			cat = catList[i]
		}
	}
	return
}
</pre></td></tr>
</table>

上の実装は暫定版である。後ほど最終版を示す。

</p>
<hr>

<p><b>2.2 ProbCatGivenDoc (暫定版)</b> --- \(P(C_i|D)\)</p>


<p>
ある文書 \(D\) がカテゴリ \(C_i\) に属する確率 
\(P(C_i|D)\) はベイズの定理により次のように表される。

\[ P(C_i|D) = \dfrac{P(C_i)P(D|C_i)}{P(D)} \]

ここで、\(P(C_i), P(D|C_i), P(D) \) はそれぞれ次の確率を示す。

<center>
<table border="1" cellspacing="0" cellpadding="5">
<tr>
<td align="center">\(P(C_i)\)</td>
<td>カテゴリー \(C_i\) である確率</td>
</tr>
<tr>
<td align="center">\(P(D|C_i)\)</td>
<td>カテゴリー \(C_i\) に文書 \(D\) が含まれる確率</td>
</tr>
<tr>
<td align="center">\(P(D)\)</td>
<td>文書 \(D\) が成立する確率</td>
</tr>
</table>
</center>
</p>


<p>
また \(P(D)\) は以下を満たす。

\[ P(D) = \Sigma_i \{P(C_i)P(D|C_i)\} \]

従って、\(P(D)\) は \(C_i\) に関係なく固定の値であること、また、

カテゴリの推定は \(P(C_i|D)\) の大小関係のみに基づいていることから、次の比例関係にのみ注目すればよい。

\[ P(C_i|D) \propto P(C_i)P(D|C_i) \]

\(P(C_i)\) を計算する関数 ProbCat と \(P(D|C_i)\) を計算する関数 ProbDocGivenCat があるとすれば、
\(P(C_i|D)\) の「比」を計算する関数 ProbCatGivenDoc の実装は次のような形になる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// ProbCatGivenDoc : 文書 doc がカテゴリ cat に含まれる確率の比を求める関数。暫定版。
func ProbDocGivenCat(doc TypeDoc, cat TypeCat) float64 {
	return ProbCat(cat) * ProbDocGivenCat(doc, cat)
}
</pre></td></tr></table>

上の実装は暫定版である。後ほど最終版を示す。

</p>


<hr>

<p><b>2.3 ProbCat</b> --- \(P(C_i)\)</p>

<p>
\(P(C_i)\) はカテゴリー \(C_i\) である確率である。

ここでは全文書における、カテゴリー \(C_i\) に属す文書の割合とみなし、
単純に文書の個数の割合で考えることにする。

\(P(C_i)\) を求める関数 ProbCat は次の実装で与えることができる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
var numAllDocs int // すべての文書の数
var numDocsCat map[TypeCat]int // 各カテゴリごとの文書の数

// ProbCat : カテゴリ cat の確率＝カテゴリ cat の文書の全文書に対する割合
func ProbCat(cat TypeCat) float64 {
    return float64(numDocsCat[cat]) / float64(numAllDocs) 
}
</pre></td></tr></table>
</p>

<hr>
<p><b>2.4 ProbDocGivenCat</b> --- \(P(D|C_i)\)</p>

<p>
\(P(D|C_i)\)はカテゴリー \(C_i\) （に属する文書群）に文書 \(D\) が含まれる確率である。

しかし文書 \(D\) がカテゴリーに属する文書と一致するケースがほぼないと考えられるため、
文書数だけでは計算することができない。


ここで文書 \(D\) に出現する単語群 \(w_j\) に注目し、次の仮定をおくことにする。

<ul>
    <li>文書は単語の並びである</li>
    <li>文書中にある単語が現れる確率は他の単語が現れる確率に依存せず独立である</li>
    <li>文書中にある単語が現れる確率は文書中の位置に依存しない</li>
</ul>

確率 \(P(w_j|C_i)=\theta_{j}\) を、文書 \(D\) に含まれる単語 \(w_j\) がカテゴリ \(C_i\) に出現する確率とし、単語 \(w_j\) が文書 \(D\) に出現する個数を \(n_{j}\) とすれば、 \(P(D|C_i)\) は次のような多項分布関数で表される。

\[P(D|C_i) = f(n_1,\cdots,n_m;\theta_{1},\cdots,\theta_{m}) = \theta_{1}^{n_1} \cdots \theta_{m}^{n_m} \] 

\[(1\le j\le m,\ 0\lt\theta_j\lt 1,\ \Sigma_j \theta_{j} = 1) \]

確率 \(P(w_j|C_i)=\theta_{j}\) を求める関数を ProbWordGivenCat とするとき、
\(P(D|C_i)\) を求める関数 ProbDocGivenCat は次のようになる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// TypeDoc : 文書の型。各単語の出現個数のmap。
type TypeDoc map[TypeWord]int
// 例：doc[word] = 単語 word が文書 doc に含まれる個数

// ProbDocGivenCat : 文書 doc がカテゴリ cat に含まれる確率
func ProbDocGivenCat(doc TypeDoc, cat TypeCat) (r float64) {
	r = 1.0
	for word, num := range doc {
		r *= math.Pow(ProbWordGivenCat(word, cat), float64(num))
	}
	return
}
</pre></td></tr></table>
</p>


<hr>
<p><b>2.5 ProbWordGivenCat</b> --- \(P(w_j|C_i)\)</p>

<p>
単語の出現確率 \(P(w_j|C_i)=\theta_{j}\) は\(P(D|C_i)\) のパラメータである。実測した単語 \(w_j\) の出現数\(n_j\)をもとに、\(P(D|C_i)\) を下に示すような尤度関数 \(L(\theta_{1},\cdots,\theta_{m})\) とみなし、これが最大になる\(\theta_{1},\cdots,\theta_{m}\) を推定することになる。

\[ L(\theta_{1},\cdots,\theta_{m}) = P(D|C_i) = \theta_{1}^{n_1} \cdots \theta_{m}^{n_m}\]

まず最尤推定値 (Maximum Likelihood Estimator) を使うこととして確率 \(P(w_j|C_i)=\theta_{j}\) を推定する関数 ProbWordGivenCat の実装を考えるが、ここで２つの案が考えられる。
</p>

<p>

<ul>
<li><b>案1</b>：カテゴリー \(C_i\) に属する文書に出現する単語群に、文書 \(D\) に出現する単語群がどれだけ含まれるかで考える。
    
    \[P(w_j|C_i) = \theta_{j} = \dfrac{単語 w_j が C_i に属す文書における出現回数の合計}{C_i に属す文書に出現する全単語の出現回数の合計} \]
    

</li>
<li><b>案2</b>：文書 \(D\) に含まれる各単語を含む文書がどれだけカテゴリー \(C_i\) に属しているかで考える。
    
    \[P(w_j|C_i) = \theta_{j} = \dfrac{単語 w_j を含みかつ C_i に属す文書の個数}{C_i に属す全文書の個数} \]    

</li>
</ul>

一つの文書には異なる単語が複数含まれることが簡単に予想されることから、案 2 では \(\Sigma_j \theta_{j} = 1\) の条件を満たすことができない。ここでは案 1 を実装する。

numWordInCat[\(C_i\)][\(w_j\)] を文書 \(D\) に含まれる単語 \(w_j\) がカテゴリ \(C_i\) に含まれる個数とすれば、\(P(w_j|C_i)\) を計算する関数 ProbWordGivenCat は次のように与えることができる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020"><pre>
// numWordInCat: ある単語があるカテゴリに含まれる個数
var numWordInCat map[TypeCat]map[TypeWord]int
// 例：numWordInCat[cat][word] = 単語 word がカテゴリ cat に含まれる個数

// numAllWordsInCat : カテゴリに含まれる個数
var numAllWordsInCat map[TypeCat]int
// 例：numAllWordsInCat[cat] = カテゴリ cat に含まれる単語の個数

// ProbWordGivenCat : 単語 word がカテゴリ cat に含まれる確率
func ProbWordGivenCat (word TypeWord, cat TypeCat) float64 {
    return float64(numWordInCat[cat][word])/float64(numAllWordsInCat[cat])
}
</pre>
</td></tr></table>

</p>

<hr>
<p><b>2.6 ProbWordGivenCat (スムージング拡張版)</b> --- \(P(w_j|C_i)\)</p>

<p>
上の実装では、文書の中に一つでもカテゴリ \(C_i\) に含まれない単語が存在すると、他の単語の確率が高いものだったとしても、全体として \(P(D|C_i)\) が 0 となってしまうという問題がある。
これを回避するため「加算スムージング」（あるいは「ラプラススムージング」）を使う。重複のない全単語の個数を \(m\) とする。 

\[P(w_j|C_i) = \theta_{j} = \dfrac{単語 w_j が C_j に属す文書における出現回数の合計 + 1 }{C_j に属す文書に出現する全単語の出現回数の合計 + m } \]

これは期待事後確率推定値 (Expected a Posterior Estimator; EAP 推定値) に相当する。
この推定値は特に標本数が少ない場合に効果があり、標本数が増えるにつれて先の最尤推定値に近づいていく。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
var numAllWords int // 全単語数

// ProbWordGivenCat : 単語 word がカテゴリ cat に含まれる確率(スムージング拡張版)
func ProbWordGivenCat (word TypeWord, cat TypeCat) float64 {
    num := float64(numWordInCat[cat][word] + 1)
    sum := float64(numAllWordsInCat + numAllWords)
    return num/sum
}
</pre></td></tr></table>

上記スムージングを施しても \(\Sigma_j \theta_{j} = 1\) の条件を満たすことに注意。

</p>

<hr>
<p><b>LogProbDocGivenCat</b> --- \(\log P(D|C_i)\)</p>

<p>
上の関数 ProbDocGivenCat の実装では、単語数が多いと分母の値が非常に大きくなりアンダーフローが起きる恐れがあるので、これを回避すべく対数をとる。

\[\log P(D|C_i) = \log f(n_1,\cdots,n_m;\theta_{1},\cdots,\theta_{m}) = n_1\log \theta_{1} + \cdots + n_m\log \theta_{m}\]


<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// TypeDoc : 文書の型。各単語の出現個数のmap。
type TypeDoc map[TypeWord]int
// 例：doc[word] = 単語 word が文書 doc に含まれる個数

// LogProbDocGivenCat : 文書 doc がカテゴリ cat に含まれる確率の対数
func LogProbDocGivenCat(doc TypeDoc, cat TypeCat) (r float64) {
	r = 0.0
	for word, num := range doc {
		r += float64(num) * math.Log(ProbWordGivenCat(word, cat))
	}
	return
}
</pre></td></tr></table>

</p>

<hr>
<br><b>2.7 LogProbCatGivenDoc</b> --- \(\log P(C_i|D)\)</p>

<p>
以上を踏まえると、冒頭に示した関数 ProbCatGivenDoc のアンダーフローを考慮した対数版 LogProbCatGivenDoc は次のようになる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// LogProbCatGivenDoc : 文書 doc がカテゴリ cat に含まれる確率の比の対数
func LogProbDocGivenCat(doc TypeDoc, cat TypeCat) float64 {
	return math.Log(ProbCat(cat)) + LogProbDocGivenCat(doc, cat)
}
</pre></td></tr></table>

</p>

<hr>
<p><b>2.8 PredictCat (最終版)</b></p>

<p>
冒頭に示した関数 PredictCat は LogProbCatGivenDoc を使って次のように実装される。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// PredictCat : 与えられた文書 doc のカテゴリを推定する
func PredictCat(doc TypeDoc) (cat TypeCat) {
	cat = catList[0]
	maxValue := LogProbCatGivenDoc(doc, cat)
	for i:=1; i&lt;len(catList); i++ {
		result := LogProbCatGivenDoc(doc, catList[i])
		if result &gt; maxValue {
			maxValue = result
			cat = catList[i]
		}
	}
	return
}
</pre></td></tr>
</table>
</p>


<hr>

<p><b>3. 学習</b></p>

<p>
	本節では 2 節に示したカテゴリの推定に必要なデータを作成するための「学習」について示す。
</p>

<hr>

<p><b>3.1 Train</b></p>

<p>
教師データとして、文書 doc とそのカテゴリ cat が与えられたとする。
使用する変数に対して、以下の表に示す処理を実施する必要がある。

<center>
<table border="1" cellspacing="0" cellpadding="5">
<tr>
<td align="center">変数</td>
<td align="center">概要</td>
<td align="center">処理</td>
<td align="center">直接的に依存する関数</td>
</tr>


<tr>
<td>var catList []TypeCat</td>
<td>カテゴリのリスト</td>
<td>cat が初出のときのみリストに追加</td>
<td>PredictCat</td>
</tr>

<tr>
<td>var numAllDocs int</td>
<td>すべての文書の数</td>
<td>numAllDocs の値をインクリメント</td>
<td>ProbCat</td>
</tr>

<tr>
<td>var numDocsCat map[TypeCat]int</td>
<td>各カテゴリごとの文書の数</td>
<td>numDocsCat[cat] の値をインクリメント</td>
<td>ProbCat</td>
</tr>

<tr>
<td>var numWordInCat map[TypeCat]map[TypeWord]int</td>
<td>ある単語があるカテゴリに含まれる個数</td>
<td>文書 doc に含まれるすべての単語 word について、numWordInCat[cat][word] の値をインクリメント</td>
<td>ProbWordGivenCat</td>
</tr>

<tr>
<td>var numAllWordsInCat map[TypeCat]int　</td>
<td>カテゴリに含まれる単語の個数</td>
<td>文書 doc に含まれる単語の個数だけ、numAllWordsInCat[cat] の値をインクリメント</td>
<td>ProbWordGivenCat</td>
</tr>

<tr>
<td>var numAllWords int</td>
<td>全単語数 (重複なし)</td>
<td>文書 doc について wordList を更新後、len(wordList) の値を代入。つまり、これまでに出現した重複のないすべての単語の個数を代入</td>
<td>ProbWordGivenCat</td>
</tr>


<tr>
<td>var wordList map[TypeWord]int</td>
<td>単語のリスト、各単語の出現数</td>
<td>文書 doc に含まれるすべての単語 word について、wordList[word] の値をインクリメント</td>
<td>Train</td>
</tr>


<!--
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
-->
</table>
</center>

与えられた文書とカテゴリで学習する関数 Train の実装例は次のようになる。

<table width="100%" cellspacing="0" cellpadding="5">
<tr><td bgcolor="#202020">
<pre>
// wordList : 単語のリスト
var wordList map[TypeWord]int

// Train : 文書 doc をカテゴリ cat として学習する
func Train(doc TypeDoc, cat TypeCat) {

	// カテゴリ cat が初出かどうか検査する
	_, ok := numDocsCat[cat]
	if !ok { // カテゴリ cat が初出の場合
		// カテゴリリストに追加
		catList = append(catList, cat)
		// カテゴリの文書を初期化
		numWordInCat[cat] = map[TypeWord]int{}
	}

	// すべての文書の数をインクリメント
	numAllDocs++

	// カテゴリ cat の文書の数をインクリメント
	numDocsCat[cat] = numDocsCat[cat] + 1

	// 文書 doc に出現する単語 word についてそれぞれ処理
	for word, num := range doc {
		// カテゴリ cat に含まれる単語の個数をインクリメント
		numAllWordsInCat[cat] = numAllWordsInCat[cat] + num  
		// 単語 word がカテゴリ cat に含まれる個数をインクリメント
		numWordInCat[cat][word] = numWordInCat[cat][word] + num
		// 単語 word を単語リストに追加。
		wordList[word] = wordList[word] + num // 単語の出現回数
	}

	// すべての単語の重複のない個数を計算
	numAllWords = len(wordList)
}
</pre></td></tr>
</table>
</p>

<hr>

<p><b>4. 評価</b></p>

<p>
	本稿に示したカテゴリの推定方式について、Livedoor ニュースコーパスを用いて精度を測定してみた。9 つのカテゴリについて、Precision, Recall, F-Measure, Accuracy の指標をまとめた表を以下に示す。

<center>
<table border="1" cellspacing="0" cellpadding="5">
<tr>
<td align="center">カテゴリ</td>
<td align="center">\(C_1\)</td>
<td align="center">\(C_2\)</td>
<td align="center">\(C_3\)</td>
<td align="center">\(C_4\)</td>
<td align="center">\(C_5\)</td>
<td align="center">\(C_6\)</td>
<td align="center">\(C_7\)</td>
<td align="center">\(C_8\)</td>
<td align="center">\(C_9\)</td>
</tr>

<tr>
<td>Precision</td>
<td>0.958084</td>
<td>0.898734</td>
<td>0.860465</td>
<td>0.930233</td>
<td>0.889535</td>
<td>0.932886</td>
<td>0.857143</td>
<td>0.937500</td>
<td>0.952941</td>
</tr>


<tr>
<td>Recall</td>
<td>1.000000</td>
<td>0.940397</td>
<td>0.907975</td>
<td>0.909091</td>
<td>0.987097</td>
<td>0.822485</td>
<td>0.814815</td>
<td>0.967742</td>
<td>0.885246</td>
</tr>

<tr>
<td>F-Measure</td>
<td>0.978593</td>
<td>0.919094</td>
<td>0.883582</td>
<td>0.919540</td>
<td>0.935780</td>
<td>0.874214</td>
<td>0.835443</td>
<td>0.952381</td>
<td>0.917847</td>
</tr>

<tr>
<td>Accuracy</td>
<td>0.995251</td>
<td>0.983039</td>
<td>0.973541</td>
<td>0.981004</td>
<td>0.985753</td>
<td>0.972863</td>
<td>0.964722</td>
<td>0.989824</td>
<td>0.980326</td>
</tr>

</table>
</center>
</p>

<p>
	全体の指標ををまとめた表を以下に示す。

<center>
<table border="1" cellspacing="0" cellpadding="5">
<tr>
<td>Micro Precision</td>
<td>0.913161</td>
</tr>

<tr>
<td>Micro Recall</td>
<td>0.913161</td>
</tr>

<tr>
<td>Micro F-Measure</td>
<td>0.913161</td>
</tr>

<tr>
<td>Macro Precision</td>
<td>0.913058</td>
</tr>

<tr>
<td>Macro Recall</td>
<td>0.914983</td>
</tr>

<tr>
<td>Macro F-Measure</td>
<td>0.914019</td>
</tr>

<tr>
<td>Overall Accuracy</td>
<td>0.980703</td>
</tr>

</table>
</center>
</p>

<p>単純な実装内容にも関わらず、高い精度でカテゴリ推定できることがわかった。</p>

<p>参考：<a href="https://www.rondhuit.com/download.html#ldcc" target="_blank">Livedoor ニュースコーパス</a></p>

<hr>

<p><b>5. おわりに</b></p>

<p>　本稿では、文書のカテゴリを推定する分類器をナイーブベイズを用いたモデルで示し、そして GoLang による実装例を示した。また、Livedoor ニュースコーパスを用いて評価した結果を示した。
</p>
<p>　今後はマルチラベル分類器に拡張していく予定である。
</p>
</body>
</html>

<!--
[sports-watch] 658 docs, 124691 words
Precision: 0.958084
Recall:    1.000000
F-Measure: 0.978593
Accuracy:  0.995251
[topic-news] 649 docs, 131553 words
Precision: 0.898734
Recall:    0.940397
F-Measure: 0.919094
Accuracy:  0.983039
[dokujo-tsushin] 679 docs, 283136 words
Precision: 0.860465
Recall:    0.907975
F-Measure: 0.883582
Accuracy:  0.973541
[it-life-hack] 628 docs, 231132 words
Precision: 0.930233
Recall:    0.909091
F-Measure: 0.919540
Accuracy:  0.981004
[movie-enter] 663 docs, 262322 words
Precision: 0.889535
Recall:    0.987097
F-Measure: 0.935780
Accuracy:  0.985753
[livedoor-homme] 657 docs, 279923 words
Precision: 0.932886
Recall:    0.822485
F-Measure: 0.874214
Accuracy:  0.972863
[peachy] 648 docs, 241316 words
Precision: 0.857143
Recall:    0.814815
F-Measure: 0.835443
Accuracy:  0.964722
[smax] 636 docs, 309270 words
Precision: 0.937500
Recall:    0.967742
F-Measure: 0.952381
Accuracy:  0.989824
[kaden-channel] 675 docs, 167068 words
Precision: 0.952941
Recall:    0.885246
F-Measure: 0.917847
Accuracy:  0.980326
[Overall] 9 categories, 5893 docs, 49322 words
Micro Precision:  0.913161
Micro Recall:     0.913161
Micro F-Measure:  0.913161
Overall Accuracy: 0.980703
Macro Precision:  0.913058
Macro Recall:     0.914983
Macro F-Measure:  0.914019
Average Accuracy: 0.980703
-->